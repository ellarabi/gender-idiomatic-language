{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze male and female embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm_notebook\n",
    "import csv\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_f = KeyedVectors.load(\"../data/wordvectors_f_final_min50.kv\", mmap='r')\n",
    "wv_m = KeyedVectors.load(\"../data/wordvectors_m_final_min50.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "def extract_idiom_groups(filename, nlp):\n",
    "    idiom_groups = {}\n",
    "    all_idioms = []\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        for row in reader:\n",
    "            if row[0]!= \"idiom\":\n",
    "                idiom = row[0]\n",
    "\n",
    "                idiom = idiom.lower().replace(\"-\", \" \")\n",
    "                idiom = idiom.replace(\",\", \"\")\n",
    "\n",
    "                group_num = row[2]\n",
    "                if group_num not in idiom_groups:\n",
    "                    idiom_groups[group_num] = []\n",
    "                idiom_groups[group_num].append(idiom)\n",
    "                all_idioms.append(idiom)\n",
    "\n",
    "    return idiom_groups, all_idioms\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "idiom_groups, all_idioms = extract_idiom_groups(\"../data/idioms-definitions-groups-for-embeddings-v2.csv\", nlp)\n",
    "\n",
    "# mapping from idioms to their generic form\n",
    "idiom2generic = {}\n",
    "for num in idiom_groups:\n",
    "    generic = \"\".join(idiom_groups[num][0].split())\n",
    "    for idiom in idiom_groups[num]:\n",
    "        idiom2generic[idiom] = generic\n",
    "\n",
    "# mapping from generic forms to all possible idioms\n",
    "generic2idiom = {}\n",
    "for idiom in idiom2generic:\n",
    "    generic = idiom2generic[idiom]\n",
    "    if generic not in generic2idiom:\n",
    "        generic2idiom[generic] = []\n",
    "    generic2idiom[generic].append(idiom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topn(wv, word, topn, restrict_vocab=None):\n",
    "    words = []\n",
    "    if word in wv:\n",
    "        for item in wv.similar_by_word(word, topn=topn, restrict_vocab=restrict_vocab):\n",
    "            words.append(item[0])\n",
    "        return words\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generic form: made inroads\n",
      "\n",
      "Neighbors in female space:\n",
      "[u'manipulate', u'convert', u'venture', u'incorporate', u'reform', u'divide', u'evolve', u'sneak', u'compete', u'drag']\n",
      "\n",
      "Neighbors in male space:\n",
      "[u'venture', u'merge', u'dominate', u'coalition', u'divided', u'evolve', u'compete', u'integrated', u'divide', u'convert']\n",
      "\n",
      "Generic form: cut it out\n",
      "\n",
      "Neighbors in female space:\n",
      "[u'quit', u'gtfo', u'chillout', u'stop', u'ignore', u'remove', u'eliminate', u'cut', u'delete', u'swallow']\n",
      "\n",
      "Neighbors in male space:\n",
      "[u'gtfo', u'quit', u'ignore', u'replace', u'remove', u'cut', u'delete', u'shave', u'skip', u'disappear']\n",
      "\n",
      "Generic form: hit and miss\n",
      "\n",
      "Neighbors in female space:\n",
      "[u'pricey', u'iffy', u'tricky', u'inconsistent', u'disappointing', u'versatile', u'tempting', u'helpful', u'confusing', u'tough']\n",
      "\n",
      "Neighbors in male space:\n",
      "[u'pricey', u'disappointing', u'tricky', u'inconsistent', u'frustrating', u'helpful', u'irritating', u'confusing', u'tough', u'sketchy']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for generic in generic2idiom:\n",
    "    \n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break\n",
    "\n",
    "    if generic not in wv_f.vocab or generic not in wv_m.vocab:\n",
    "        continue\n",
    "        \n",
    "    words_f = extract_topn(wv_f, generic, topn=10, restrict_vocab=10000)    \n",
    "    words_m = extract_topn(wv_m, generic, topn=10, restrict_vocab=10000)\n",
    "    \n",
    "    if words_f and words_m:\n",
    "        print(\"\\nGeneric form: \" + generic2idiom[generic][0])\n",
    "        print(\"\\nNeighbors in female space:\")\n",
    "        print(words_f)\n",
    "        print(\"\\nNeighbors in male space:\")\n",
    "        print(words_m)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by intersection or by averaged intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import operator\n",
    "\n",
    "def compute_intersections(average_version=False):\n",
    "    intersections = {}\n",
    "    \n",
    "    for generic in tqdm_notebook(generic2idiom):\n",
    "        \n",
    "        if generic not in wv_f.vocab or generic not in wv_m.vocab:\n",
    "            continue\n",
    "\n",
    "        words_f = extract_topn(wv_f, generic, topn=100, restrict_vocab=10000)\n",
    "        words_m = extract_topn(wv_m, generic, topn=100, restrict_vocab=10000)\n",
    "        \n",
    "        if words_f and words_m: \n",
    "            if average_version:\n",
    "                intersections[generic] = 0.0\n",
    "                for i in range(100):\n",
    "                    intersections[generic] += len(set(words_f[:i]).intersection(words_m[:i]))/float(i+1)\n",
    "                intersections[generic] /= 100\n",
    "            else:\n",
    "                intersections[generic] = len(set(words_f).intersection(words_m))\n",
    "\n",
    "    return intersections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd409f49d9494fcfbab86a209cefcf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "intersections = compute_intersections()\n",
    "sorted_intersections = sorted(intersections.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4c943bf67848ec824d89f95fc80281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "average_intersections = compute_intersections(average_version=True)\n",
    "sorted_average_intersections = sorted(average_intersections.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print most different and least different idioms across genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_details(sorted_intersections):\n",
    "    \n",
    "    for idiom, intersection in sorted_intersections:\n",
    "        print(generic2idiom[idiom][0], intersection)\n",
    "        words_f = extract_topn(wv_f, idiom, topn=10, restrict_vocab=10000)\n",
    "        words_m = extract_topn(wv_m, idiom, topn=10, restrict_vocab=10000)\n",
    "        only_f = set(words_f) - set(words_m)\n",
    "        only_m = set(words_m) - set(words_f)\n",
    "        both = set(words_f) - set(only_f)\n",
    "        print(\"\\nNN of both:\\n\")\n",
    "        print(list(both))\n",
    "        print(\"\\nNN of only female:\\n\")\n",
    "        print(list(only_f))\n",
    "        print(\"\\nNN of only male:\\n\")\n",
    "        print(list(only_m))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idioms used differently\n",
      "========================\n",
      "\n",
      "('hard as nails', 0)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[]\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'foundation', u'eyeshadow', u'lipstick', u'coat', u'revlon', u'eyeliner', u'nail', u'polish', u'sally', u'gel']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'fantastic', u'tough', u'brilliant', u'phenomenal', u'dope', u'gorgeous', u'brutal', u'hilarious', u'badass', u'adorable']\n",
      "('catnap', 3)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[]\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'sip', u'naps', u'bite', u'kitty', u'bath', u'nap', u'cuddle', u'cat', u'snuggle', u'fetch']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'cleric', u'wizard', u'magic', u'spell', u'breath', u'arcane', u'bard', u'initiative', u'feat', u'spells']\n",
      "\n",
      "Idioms used similarly\n",
      "======================\n",
      "('give me five', 81)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[u'20', u'thirty', u'ten', u'twenty', u'fifty', u'five', u'fifteen']\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'30', u'15', u'45']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'twelve', u'seven', u'eight']\n",
      "('lo and behold', 75)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[u'thankfully', u'fortunately', u'whoops', u'yesterday', u'welp', u'luckily', u'bam']\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'finally', u'boom', u'promptly']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'grabbed', u'upstairs', u'oops']\n"
     ]
    }
   ],
   "source": [
    "print(\"Idioms used differently\\n========================\\n\")\n",
    "print_details(sorted_intersections[:2])\n",
    "print(\"\\nIdioms used similarly\\n======================\")\n",
    "print_details(sorted_intersections[-2:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idioms used differently\n",
      "========================\n",
      "\n",
      "('hard as nails', 0.0)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[]\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'foundation', u'eyeshadow', u'lipstick', u'coat', u'revlon', u'eyeliner', u'nail', u'polish', u'sally', u'gel']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'fantastic', u'tough', u'brilliant', u'phenomenal', u'dope', u'gorgeous', u'brutal', u'hilarious', u'badass', u'adorable']\n",
      "('nothing doing', 0.014298110795516359)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[]\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'town', u'36', u'bust', u'tech', u'72', u'branch', u'cs', u'rural', u'farming', u'local']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'gg', u'nevermind', u'yesterday', u\":'(\", u'0', u'awww', u'bam', u'welp', u'ew', u'bye']\n",
      "\n",
      "Idioms used similarly\n",
      "======================\n",
      "('give me five', 0.7652691795756873)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[u'20', u'thirty', u'ten', u'twenty', u'fifty', u'five', u'fifteen']\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'30', u'15', u'45']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'twelve', u'seven', u'eight']\n",
      "('on the hook', 0.7101561409263808)\n",
      "\n",
      "NN of both:\n",
      "\n",
      "[u'paying', u'owed', u'sued', u'eligible', u'responsible', u'paid', u'punished', u'charged']\n",
      "\n",
      "NN of only female:\n",
      "\n",
      "[u'unemployed', u'accountable']\n",
      "\n",
      "NN of only male:\n",
      "\n",
      "[u'begging', u'liable']\n"
     ]
    }
   ],
   "source": [
    "print(\"Idioms used differently\\n========================\\n\")\n",
    "print_details(sorted_average_intersections[:2])\n",
    "print(\"\\nIdioms used similarly\\n======================\")\n",
    "print_details(sorted_average_intersections[-2:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
